model:
  base_learning_rate: 1.0e-4
  target: sgm.models.diffusion.ResidualDiffusionEngine
  params:
    input_key: "target"
    mean_key: "S2"
    compile_model: False
    use_ema: True
    use_flash_attn2: False

    sigma_st_config:
      target: sgm.modules.diffusionmodules.sigma2st.EDMSigma2St
      params:
        alpha: 1.0

    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.ResidualDenoiser
      params:
        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.ResidualEDMScaling
          params:
            sigma_input: 1.0
            sigma_mu: 1.0

    network_wrapper: "sgm.modules.diffusionmodules.wrappers.CloudRemovalWrapper"

    network_config:
      target: sgm.modules.diffusionmodules.k_diffusion.image_unet_TemporalAdm.UNetModel # 
      params:
        image_size: 256
        in_channels: 28
        model_channels : 64
        condition_net_multiple : 1
        out_channels: 13
        num_res_blocks: 2 # 4
        attention_resolutions : [32] #[32,16,8]
        sequence_length : 1
        dropout: 0
        channel_mult: [1, 2, 4]
        attention_names: ['local','local','local','local']
        middle_attention_patch: [1,1]
        patch_size : [4,4]
        conv_resample: True
        dims: 2
        use_checkpoint: False
        use_fp16: False
        num_heads: 1
        num_head_channels: -1
        num_heads_upsample: -1
        use_scale_shift_norm: True
        resblock_updown: True
        use_new_attention_order: False
        time_emb_fourier : True
        # control_mode:  "sum" # "conv"

    conditioner_config:
      target: sgm.modules.GeneralConditioner
      params:
        emb_models:
          - is_trainable: True
            input_key:  "S1S2"
            ucg_rate: 0.0
            target: sgm.modules.encoders.modules.IndentityEmbedder 
          # - is_trainable: True
          #   input_key:  "S1"
          #   ucg_rate: 0.0
          #   target: sgm.modules.encoders.modules.ImageTransformerEncoderInterface
          #   params:
          #     in_channels: 2
          #     patch_size: [4,4]
          #     widths: [256,512,768]
          #     depths: [2,2,16]
          #     d_ffs: [512,1024,1536]
          #     self_attns: [
          #         {"type": "neighborhood", "d_head": 64, "kernel_size": 7},
          #         {"type": "neighborhood", "d_head": 64, "kernel_size": 7},
          #         {"type": "global", "d_head": 64},
          #     ]
          #     dropout_rate: [0.0,0.0,0.0]

    first_stage_config:
      target: sgm.models.autoencoder.IdentityFirstStage

    loss_fn_config:
      target: sgm.modules.diffusionmodules.loss.ResidualDiffusion_Alpha_YUV
      params:
        rgb2yuv_config:
          target: sgm.util.rgb2yuv_s1s2_minus1_1
        yuv_multiple : 1.0
        attention_multiple : 3.0
        unattention_multiple : 1.0
        threshold : 1.0
        loss_weighting_config:
          target: sgm.modules.diffusionmodules.loss_weighting.ResidualEDMWeighting # ResidualSoftMinSnrWeighting
          params:
            sigma_input: 1.0
            sigma_mu: 1.0
        sigma_sampler_config:
          target: sgm.modules.diffusionmodules.sigma_sampling.EDMSampling
          params:
            p_mean: -1.4
            p_std: 1.4

    sampler_config:
      target: sgm.modules.diffusionmodules.sampling.ResidualEulerEDMSampler
      params:
        num_steps: 4
        s_churn: 0.1
        s_tmin: 0.0
        s_tmax: 100000000.0
        s_noise: 0.0

        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.EDMDiscretization
          params:
            sigma_min: 0.001
            sigma_max: 110.0
    
    to_rgb_config:
      target: sgm.util.S1andS2_to_rgb

data:
  target: sgm.data.base.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 8
    wrap: True
    train:
      target: sgm.data.sentinel.sentinel.SEN12MSCRInterface
      params:
        root: "/mnt/data2/sw/chenqa/RS/datasets" # download SEN12MSCR dataset, and change the path of images here
        split: "train"
        region: "all" # the region of data you want to use, see ../sgm/data/sentinel/sentinel.py for more details
        rescale: True
        cloud_masks:

    validation:
      target: sgm.data.sentinel.sentinel.SEN12MSCRInterface
      params:
        root: "/mnt/data2/sw/chenqa/RS/datasets" # download SEN12MSCR dataset, and change the path of images here
        split: "val"
        region: "all"
        rescale: True
        cloud_masks:

    test:
      target: sgm.data.sentinel.sentinel.SEN12MSCRInterface
      params:
        root: "/mnt/data2/sw/chenqa/RS/datasets" # download SEN12MSCR dataset, and change the path of images here
        split: "test"
        region: "all"
        rescale: True
        cloud_masks:

    predict:
      target: sgm.data.sentinel.sentinel.SEN12MSCRInterface
      params:
        root: "/mnt/data2/sw/chenqa/RS/datasets" # download SEN12MSCR dataset, and change the path of images here
        split: "test"
        region: "all"
        rescale: True
        cloud_masks:

lightning:
  modelcheckpoint:
    params:
      every_n_train_steps: 5000
      monitor: "RMSE"

  callbacks:
    metrics_over_trainsteps_checkpoint:
      params:
        every_n_train_steps: 25000

    image_logger:
      target: main.ImageLogger
      params:
        disabled: False
        batch_frequency: 1000
        max_images: 64
        increase_log_steps: True
        log_first_step: False
        log_images_kwargs:
          use_ema_scope: False
          N: 64
          n_rows: 16
          return_intermediate: True
          return_denoised: True
          return_add_mu: True
          return_add_noise: True
          return_cond: True

  trainer:
    devices: 0, # The GPUs you want to use
    num_sanity_val_steps: 0
    benchmark: True
    accumulate_grad_batches: 1
    max_epochs: 100